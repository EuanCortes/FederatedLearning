{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import copy\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "import torch\n",
    "from torchvision.datasets import CIFAR10\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "batch_size = 64\n",
    "batch_size_test = 64\n",
    "\n",
    "trainset = CIFAR10(root='./data', train=True,\n",
    "                   download=True, transform=transform)\n",
    "#trainloader = DataLoader(trainset, batch_size=batch_size,\n",
    "#                         shuffle=True, num_workers=2)\n",
    "\n",
    "testset = CIFAR10(root='./data', train=False,\n",
    "                  download=True, transform=transform)\n",
    "testloader = DataLoader(testset, batch_size=batch_size_test,\n",
    "                        shuffle=False, num_workers=0)\n",
    "\n",
    "classes = ('plane', 'car', 'bird', 'cat',\n",
    "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device: cuda:0\n"
     ]
    }
   ],
   "source": [
    "class SmallCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SmallCNN, self).__init__()\n",
    "\n",
    "        self.ConvLayers = nn.ModuleList([\n",
    "            nn.Conv2d(3, 32, kernel_size=3, padding=1),   # N x 3 x 32 x 32 -> N x 32 x 32 x 32\n",
    "            nn.Conv2d(32, 64, kernel_size=3, padding=1),  # N x 32 x 16 x 16 -> N x 64 x 16 x 16\n",
    "            nn.Conv2d(64, 128, kernel_size=3, padding=1), # N x 64 x 8 x 8 -> N x 128 x 8 x 8\n",
    "        ])\n",
    "\n",
    "        self.BatchNorms = nn.ModuleList([\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.BatchNorm2d(128),\n",
    "        ])\n",
    "\n",
    "        self.fc1 = nn.Linear(128 * 4 * 4, 256)\n",
    "        self.fc2 = nn.Linear(256, 10)\n",
    "\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(0.2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        for conv, batchnorm in zip(self.ConvLayers, self.BatchNorms):\n",
    "            x = batchnorm(conv(x))\n",
    "            x = self.pool(self.relu(x))       # final shape: N x 128 x 4 x 4\n",
    "        x = x.view(x.size(0), -1)                   # reshape to N x 128*4*4\n",
    "        x = self.relu(self.fc1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"device: {device}\")\n",
    "net = SmallCNN().to(device)\n",
    "\n",
    "init_weights = copy.deepcopy(net.state_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Samples per client: 500\n",
      "Clients per round: 10\n"
     ]
    }
   ],
   "source": [
    "NUM_CLIENTS = 100\n",
    "IID_DATA = True\n",
    "\n",
    "data_size = len(trainset)\n",
    "\n",
    "#create indices for each client\n",
    "if IID_DATA:\n",
    "    client_indices = torch.tensor_split(torch.randperm(data_size), NUM_CLIENTS)\n",
    "else:\n",
    "    raise NotImplementedError(\"Non-IID data not implemented\")\n",
    "\n",
    "print(f\"Samples per client: {len(client_indices[0]):d}\")\n",
    "\n",
    "clientloaders = [DataLoader(Subset(trainset, indices), batch_size=batch_size, shuffle=True) for indices in client_indices]\n",
    "\n",
    "NUM_ROUNDS = 20\n",
    "NUM_LOCAL_EPOCHS = 10\n",
    "C = 0.1\n",
    "\n",
    "CLIENTS_PER_ROUND = int(NUM_CLIENTS * C)\n",
    "\n",
    "print(f\"Clients per round: {CLIENTS_PER_ROUND:d}\")\n",
    "\n",
    "LR = 0.001\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Round 1 done\n",
      "training loss: 0.470\n",
      "Federated Averaging done\n",
      "Round 2 done\n",
      "training loss: 0.271\n",
      "Federated Averaging done\n",
      "Round 3 done\n",
      "training loss: 0.145\n",
      "Federated Averaging done\n",
      "Round 4 done\n",
      "training loss: 0.105\n",
      "Federated Averaging done\n",
      "Round 5 done\n",
      "training loss: 0.089\n",
      "Federated Averaging done\n",
      "Test accuracy in round 5: 64 %\n",
      "Round 6 done\n",
      "training loss: 0.083\n",
      "Federated Averaging done\n",
      "Round 7 done\n",
      "training loss: 0.064\n",
      "Federated Averaging done\n",
      "Round 8 done\n",
      "training loss: 0.074\n",
      "Federated Averaging done\n",
      "Round 9 done\n",
      "training loss: 0.071\n",
      "Federated Averaging done\n",
      "Round 10 done\n",
      "training loss: 0.067\n",
      "Federated Averaging done\n",
      "Test accuracy in round 10: 69 %\n",
      "Round 11 done\n",
      "training loss: 0.061\n",
      "Federated Averaging done\n",
      "Round 12 done\n",
      "training loss: 0.057\n",
      "Federated Averaging done\n",
      "Round 13 done\n",
      "training loss: 0.065\n",
      "Federated Averaging done\n",
      "Round 14 done\n",
      "training loss: 0.041\n",
      "Federated Averaging done\n",
      "Round 15 done\n",
      "training loss: 0.055\n",
      "Federated Averaging done\n",
      "Test accuracy in round 15: 69 %\n",
      "Round 16 done\n",
      "training loss: 0.056\n",
      "Federated Averaging done\n",
      "Round 17 done\n",
      "training loss: 0.064\n",
      "Federated Averaging done\n",
      "Round 18 done\n",
      "training loss: 0.056\n",
      "Federated Averaging done\n",
      "Round 19 done\n",
      "training loss: 0.057\n",
      "Federated Averaging done\n",
      "Round 20 done\n",
      "training loss: 0.072\n",
      "Federated Averaging done\n",
      "Test accuracy in round 20: 71 %\n"
     ]
    }
   ],
   "source": [
    "avg_test_loss = []\n",
    "\n",
    "current_weights = copy.deepcopy(init_weights)\n",
    "\n",
    "for round in range(NUM_ROUNDS):     # iterate thru rounds\n",
    "\n",
    "    clients = torch.randperm(NUM_CLIENTS)[:CLIENTS_PER_ROUND] # random selection of clients to participate\n",
    "\n",
    "    local_weights = []\n",
    "    temp_avg_loss = 0\n",
    "    for client in clients:   # iterate thru clients\n",
    "\n",
    "        net.load_state_dict(current_weights)    # load global weights\n",
    "        net.train()                             # set model to train mode\n",
    "\n",
    "        optimizer = optim.Adam(net.parameters(), lr=LR, weight_decay=0)\n",
    "\n",
    "        clientloader = clientloaders[client]\n",
    "        client_loss = 0\n",
    "        for local_epoch in range(NUM_LOCAL_EPOCHS):     # iterate thru local epochs\n",
    "            \n",
    "            epoch_loss = 0\n",
    "            for Xlocal, Ylocal in clientloader:     # iterate thru local data\n",
    "                Xlocal, Ylocal = Xlocal.to(device), Ylocal.to(device)\n",
    "\n",
    "                outputs = net(Xlocal)\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "                loss = criterion(outputs, Ylocal)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "            \n",
    "                epoch_loss += loss.item() \n",
    "\n",
    "        temp_avg_loss += epoch_loss / len(clientloader)   # average loss per client\n",
    "        local_weights.append(copy.deepcopy(net.state_dict()))\n",
    "    \n",
    "    avg_test_loss.append(temp_avg_loss / CLIENTS_PER_ROUND)\n",
    "    \n",
    "    print(f\"Round {round+1} done\")\n",
    "    print(f\"training loss: {avg_test_loss[-1]:.3f}\")\n",
    "    # average local weights\n",
    "    new_weights = {}\n",
    "    for key in current_weights:\n",
    "        new_weights[key] = torch.stack([local_weights[i][key] for i in range(CLIENTS_PER_ROUND)]).sum(0) / CLIENTS_PER_ROUND\n",
    "    \n",
    "    print(\"Federated Averaging done\")\n",
    "\n",
    "    current_weights = new_weights\n",
    "\n",
    "    if round % 5 == 4:\n",
    "        net.load_state_dict(current_weights)\n",
    "        net.eval()\n",
    "\n",
    "        correct = 0\n",
    "        total = 0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for (images, labels) in testloader:\n",
    "                images, labels = images.to(device), labels.to(device)\n",
    "                # calculate outputs by running images through the network\n",
    "                outputs = net(images)\n",
    "                # the class with the highest energy is what we choose as prediction\n",
    "                _, predicted = torch.max(outputs, 1)\n",
    "                total += labels.size(0)\n",
    "                correct += (predicted == labels).sum().item()\n",
    "\n",
    "        print(f'Test accuracy in round {round+1:d}: {100 * correct // total} %')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "FLenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
