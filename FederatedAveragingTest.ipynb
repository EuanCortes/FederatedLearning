{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import copy\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "import torch\n",
    "from torchvision.datasets import CIFAR10\n",
    "from torch.utils.data import DataLoader, Subset, random_split\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the transformation of the data. \n",
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),     # convert the image to a pytorch tensor\n",
    "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))]) # normalise the image with mean and std of 0.5\n",
    "\n",
    "batch_size = 64     # define the batch size\n",
    "\n",
    "trainset = CIFAR10(root='./data', train=True,\n",
    "                   download=True, transform=transform)\n",
    "\n",
    "# split the training set into 80% training and 20% validation\n",
    "train_size = int(0.8 * len(trainset))\n",
    "val_size = len(trainset) - train_size\n",
    "\n",
    "train_dataset, val_dataset = random_split(trainset, [train_size, val_size]) #generate random training and validation sets\n",
    "\n",
    "valloader = DataLoader(val_dataset, batch_size=batch_size,\n",
    "                        shuffle=False, num_workers=0)\n",
    "\n",
    "# load test data\n",
    "testset = CIFAR10(root='./data', train=False,\n",
    "                  download=True, transform=transform)\n",
    "testloader = DataLoader(testset, batch_size=batch_size,\n",
    "                        shuffle=False, num_workers=0)\n",
    "\n",
    "\n",
    "# define classes\n",
    "classes = ('plane', 'car', 'bird', 'cat',\n",
    "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device: cuda:0\n",
      "Trainable parameters: 620810\n"
     ]
    }
   ],
   "source": [
    "class SmallCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SmallCNN, self).__init__()\n",
    "\n",
    "        self.relu = nn.ReLU()               # activation function\n",
    "\n",
    "        # convcolutional layers\n",
    "        self.ConvLayers = nn.ModuleList([\n",
    "            nn.Conv2d(3, 32, kernel_size=3, padding=1),   # N x 3 x 32 x 32 -> N x 32 x 32 x 32\n",
    "            nn.Conv2d(32, 64, kernel_size=3, padding=1),  # N x 32 x 16 x 16 -> N x 64 x 16 x 16\n",
    "            nn.Conv2d(64, 128, kernel_size=3, padding=1), # N x 64 x 8 x 8 -> N x 128 x 8 x 8\n",
    "        ])\n",
    "\n",
    "        # batch normalization layers (for regularization)\n",
    "        self.BatchNorms = nn.ModuleList([\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.BatchNorm2d(128),\n",
    "        ])\n",
    "\n",
    "        self.fc1 = nn.Linear(128 * 4 * 4, 256)      # first fully connected layer after convolutional layers\n",
    "        self.fc2 = nn.Linear(256, 10)               # final fully connected layer for output\n",
    "\n",
    "        self.pool = nn.MaxPool2d(2, 2)      # max pooling layer for regularization\n",
    "        self.dropout = nn.Dropout(0.2)      # dropout layer for regularization\n",
    "\n",
    "    def forward(self, x):\n",
    "        for conv, batchnorm in zip(self.ConvLayers, self.BatchNorms):\n",
    "            # apply convolutional layer, then batch normalization, then ReLU, then max pooling\n",
    "            x = batchnorm(conv(x))\n",
    "            x = self.pool(self.relu(x))       # final shape: N x 128 x 4 x 4\n",
    "\n",
    "        x = x.view(x.size(0), -1)       # reshape to N x 128*4*4\n",
    "        x = self.relu(self.fc1(x))      # fully connected layer and ReLU\n",
    "        x = self.dropout(x)             # apply dropout for regularization\n",
    "        x = self.fc2(x)                 # final fully connected layer for output\n",
    "        return x\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"device: {device}\")\n",
    "net = SmallCNN().to(device)\n",
    "\n",
    "trainable_params = sum(p.numel() for p in net.parameters() if p.requires_grad)\n",
    "print(\"Trainable parameters:\", trainable_params)\n",
    "\n",
    "init_weights = copy.deepcopy(net.state_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Client:\n",
    "    '''\n",
    "    Class that represents clients in a federated learning system.\n",
    "    The client should maintain a fixed local dataset, and\n",
    "    contain a method that can be called to train the model locally\n",
    "    when participating in a round of federated learning.\n",
    "    '''\n",
    "\n",
    "    def __init__(self, net, data, batch_size, criterion, device=None, LR=0.001, weight_decay=0):\n",
    "        '''\n",
    "        Constructor for the Client class.\n",
    "        :param net:         the neural network model\n",
    "        :param data:        the local dataset\n",
    "        :param batch_size:  the batch size to use for training\n",
    "        :param optimizer:   the optimizer to use for training\n",
    "        :param criterion:   the loss function to use for training\n",
    "        :param device:      the device to run the training on (cpu or cuda)\n",
    "        '''\n",
    "        self.net = net.to(device)\n",
    "        self.data = data\n",
    "        self.batch_size = batch_size\n",
    "        self.criterion = criterion\n",
    "\n",
    "        # set device to run the training on\n",
    "        if device is None:\n",
    "            self.device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "        else:\n",
    "            self.device = device\n",
    "\n",
    "        # create a DataLoader for the local dataset\n",
    "        self.dataloader = DataLoader(data, batch_size=batch_size,\n",
    "                                    shuffle=True, num_workers=0)\n",
    "        \n",
    "        # set optimizer\n",
    "        self.optimizer = optim.Adam(net.parameters(), lr=LR, weight_decay=weight_decay)\n",
    "\n",
    "    def train(self, epochs, state_dict):\n",
    "        '''\n",
    "        Training method that trains the model on the local dataset for a number of epochs.\n",
    "        :param epochs:      the number of epochs to train\n",
    "        :param state_dict:  the state dictionary of the global model\n",
    "\n",
    "        :return:            the state dictionary of the trained model and the loss\n",
    "        '''\n",
    "\n",
    "        self.net.load_state_dict(state_dict)    # load global weights\n",
    "        self.net.train()                             # set model to train mode\n",
    "\n",
    "        for epoch in range(epochs):     # iterate thru local epochs\n",
    "            \n",
    "            epoch_loss = 0\n",
    "            for Xtrain, Ytrain in self.dataloader:     # iterate thru local data\n",
    "                Xtrain, Ytrain = Xtrain.to(self.device), Ytrain.to(self.device)\n",
    "\n",
    "                outputs = self.net(Xtrain)\n",
    "\n",
    "                self.optimizer.zero_grad()\n",
    "                loss = self.criterion(outputs, Ytrain)\n",
    "                loss.backward()\n",
    "                self.optimizer.step()\n",
    "            \n",
    "                epoch_loss += loss.item() \n",
    "\n",
    "        return copy.deepcopy(self.net.state_dict()), epoch_loss / len(self.dataloader)\n",
    "\n",
    "\n",
    "\n",
    "def client_update(cuda_id : int, \n",
    "                  dataloader : DataLoader, \n",
    "                  state_dict : dict, \n",
    "                  criterion=nn.CrossEntropyLoss(), \n",
    "                  epochs=5,\n",
    "                  lr=0.001, \n",
    "                  weight_decay=0):\n",
    "    '''\n",
    "    client update method for parallelisation\n",
    "    :param cuda_id:     the cuda device id to use\n",
    "    :param dataloader:  the dataloader for the local dataset\n",
    "    :param state_dict:  the state dictionary of the global model\n",
    "    :param criterion:   the loss function to use for training\n",
    "    :param epochs:      the number of epochs to train\n",
    "    :param lr:          the learning rate for training\n",
    "    :param weight_decay: the weight decay for training\n",
    "\n",
    "    return:             the state dictionary of the trained model and the average batch loss\n",
    "    '''\n",
    "    device = torch.device(f\"cuda:{cuda_id}\")\n",
    "    net = SmallCNN().to(device)\n",
    "    net.load_state_dict(state_dict)\n",
    "    optimizer = optim.Adam(net.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "    net.train()\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        epoch_loss = 0\n",
    "        for Xtrain, Ytrain in dataloader:\n",
    "            Xtrain, Ytrain = Xtrain.to(device), Ytrain.to(device)\n",
    "\n",
    "            outputs = net(Xtrain)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss = criterion(outputs, Ytrain)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            epoch_loss += loss.item()\n",
    "    \n",
    "    return copy.deepcopy(net.state_dict()), epoch_loss / len(dataloader)\n",
    "\n",
    "\n",
    "def FedAvg(state_dicts, weights=None):\n",
    "    '''\n",
    "    Function that averages the weights of the models in the input list.\n",
    "    :param state_dicts:     list of state dictionaries of the models to average\n",
    "    :param weights:         list of weights to use for the averaging\n",
    "\n",
    "    :return:                the state dictionary of the averaged model\n",
    "    '''\n",
    "    avg_state = copy.deepcopy(state_dicts[0])   # copy the first model's weights \n",
    "\n",
    "    for key in avg_state.keys():    # iterate thru the module weights\n",
    "\n",
    "        if weights is not None:     # if weights are provided, use them for the averaging\n",
    "            avg_state[key] = state_dicts[0][key] * weights[0]\n",
    "\n",
    "        for i in range(1, len(state_dicts)):\n",
    "            \n",
    "            if weights is not None:     # if weights are provided, use them for the averaging\n",
    "                avg_state[key] += state_dicts[i][key] * weights[i]\n",
    "\n",
    "            else:\n",
    "                avg_state[key] += state_dicts[i][key]\n",
    "\n",
    "        avg_state[key] = avg_state[key] / len(state_dicts)\n",
    "\n",
    "    return avg_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Samples per client: 400\n",
      "Clients per round: 10\n"
     ]
    }
   ],
   "source": [
    "NUM_CLIENTS = 100        # number of clients\n",
    "IID_DATA = True          # whether the data is IID or not\n",
    "NUM_ROUNDS = 100         # number of rounds of federated learning\n",
    "NUM_LOCAL_EPOCHS = 5     # number of local epochs\n",
    "C = 0.1                  # fraction of clients to use per round\n",
    "CLIENTS_PER_ROUND = int(NUM_CLIENTS * C)    # number of clients to use per round\n",
    "LR = 0.001                      # learning rate\n",
    "DATA_SIZE = len(train_dataset)  # size of the training dataset\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "#create indices for each client\n",
    "if IID_DATA:\n",
    "    client_indices = torch.tensor_split(torch.randperm(DATA_SIZE), NUM_CLIENTS)\n",
    "else:\n",
    "    raise NotImplementedError(\"Non-IID data not implemented\")\n",
    "\n",
    "clients = [\n",
    "    Client(net=SmallCNN(), \n",
    "           data=Subset(train_dataset, indices), \n",
    "           batch_size=batch_size, \n",
    "           criterion=criterion, \n",
    "           device=device, \n",
    "           LR=LR)\n",
    "    for indices in client_indices\n",
    "]\n",
    "\n",
    "print(f\"Samples per client: {len(client_indices[0]):d}\")\n",
    "print(f\"Clients per round: {CLIENTS_PER_ROUND:d}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Round 1 done\n",
      "training loss: 1.331\n",
      "Federated Averaging done\n",
      "Round 2 done\n",
      "training loss: 1.134\n",
      "Federated Averaging done\n",
      "Round 3 done\n",
      "training loss: 0.881\n",
      "Federated Averaging done\n",
      "Round 4 done\n",
      "training loss: 0.795\n",
      "Federated Averaging done\n",
      "Round 5 done\n",
      "training loss: 0.710\n",
      "Federated Averaging done\n",
      "Validation accuracy in round 5: 57 %\n",
      "Round 6 done\n",
      "training loss: 0.667\n",
      "Federated Averaging done\n",
      "Round 7 done\n",
      "training loss: 0.556\n",
      "Federated Averaging done\n",
      "Round 8 done\n",
      "training loss: 0.449\n",
      "Federated Averaging done\n",
      "Round 9 done\n",
      "training loss: 0.393\n",
      "Federated Averaging done\n",
      "Round 10 done\n",
      "training loss: 0.413\n",
      "Federated Averaging done\n",
      "Validation accuracy in round 10: 63 %\n",
      "Round 11 done\n",
      "training loss: 0.341\n",
      "Federated Averaging done\n",
      "Round 12 done\n",
      "training loss: 0.337\n",
      "Federated Averaging done\n",
      "Round 13 done\n",
      "training loss: 0.307\n",
      "Federated Averaging done\n",
      "Round 14 done\n",
      "training loss: 0.325\n",
      "Federated Averaging done\n",
      "Round 15 done\n",
      "training loss: 0.255\n",
      "Federated Averaging done\n",
      "Validation accuracy in round 15: 68 %\n",
      "Round 16 done\n",
      "training loss: 0.293\n",
      "Federated Averaging done\n",
      "Round 17 done\n",
      "training loss: 0.231\n",
      "Federated Averaging done\n",
      "Round 18 done\n",
      "training loss: 0.246\n",
      "Federated Averaging done\n",
      "Round 19 done\n",
      "training loss: 0.171\n",
      "Federated Averaging done\n",
      "Round 20 done\n",
      "training loss: 0.190\n",
      "Federated Averaging done\n",
      "Validation accuracy in round 20: 69 %\n",
      "Round 21 done\n",
      "training loss: 0.157\n",
      "Federated Averaging done\n",
      "Round 22 done\n",
      "training loss: 0.180\n",
      "Federated Averaging done\n",
      "Round 23 done\n",
      "training loss: 0.177\n",
      "Federated Averaging done\n",
      "Round 24 done\n",
      "training loss: 0.153\n",
      "Federated Averaging done\n",
      "Round 25 done\n",
      "training loss: 0.148\n",
      "Federated Averaging done\n",
      "Validation accuracy in round 25: 71 %\n",
      "Round 26 done\n",
      "training loss: 0.133\n",
      "Federated Averaging done\n",
      "Round 27 done\n",
      "training loss: 0.134\n",
      "Federated Averaging done\n",
      "Round 28 done\n",
      "training loss: 0.120\n",
      "Federated Averaging done\n",
      "Round 29 done\n",
      "training loss: 0.122\n",
      "Federated Averaging done\n",
      "Round 30 done\n",
      "training loss: 0.103\n",
      "Federated Averaging done\n",
      "Validation accuracy in round 30: 71 %\n",
      "Round 31 done\n",
      "training loss: 0.109\n",
      "Federated Averaging done\n",
      "Round 32 done\n",
      "training loss: 0.100\n",
      "Federated Averaging done\n",
      "Round 33 done\n",
      "training loss: 0.103\n",
      "Federated Averaging done\n",
      "Round 34 done\n",
      "training loss: 0.121\n",
      "Federated Averaging done\n",
      "Round 35 done\n",
      "training loss: 0.077\n",
      "Federated Averaging done\n",
      "Validation accuracy in round 35: 72 %\n",
      "Round 36 done\n",
      "training loss: 0.097\n",
      "Federated Averaging done\n",
      "Round 37 done\n",
      "training loss: 0.088\n",
      "Federated Averaging done\n",
      "Round 38 done\n",
      "training loss: 0.087\n",
      "Federated Averaging done\n",
      "Round 39 done\n",
      "training loss: 0.082\n",
      "Federated Averaging done\n",
      "Round 40 done\n",
      "training loss: 0.076\n",
      "Federated Averaging done\n",
      "Validation accuracy in round 40: 73 %\n",
      "Round 41 done\n",
      "training loss: 0.077\n",
      "Federated Averaging done\n",
      "Round 42 done\n",
      "training loss: 0.101\n",
      "Federated Averaging done\n",
      "Round 43 done\n",
      "training loss: 0.084\n",
      "Federated Averaging done\n",
      "Round 44 done\n",
      "training loss: 0.078\n",
      "Federated Averaging done\n",
      "Round 45 done\n",
      "training loss: 0.066\n",
      "Federated Averaging done\n",
      "Validation accuracy in round 45: 73 %\n",
      "Round 46 done\n",
      "training loss: 0.068\n",
      "Federated Averaging done\n",
      "Round 47 done\n",
      "training loss: 0.077\n",
      "Federated Averaging done\n",
      "Round 48 done\n",
      "training loss: 0.054\n",
      "Federated Averaging done\n",
      "Round 49 done\n",
      "training loss: 0.066\n",
      "Federated Averaging done\n",
      "Round 50 done\n",
      "training loss: 0.079\n",
      "Federated Averaging done\n",
      "Validation accuracy in round 50: 74 %\n",
      "Round 51 done\n",
      "training loss: 0.084\n",
      "Federated Averaging done\n",
      "Round 52 done\n",
      "training loss: 0.087\n",
      "Federated Averaging done\n",
      "Round 53 done\n",
      "training loss: 0.056\n",
      "Federated Averaging done\n",
      "Round 54 done\n",
      "training loss: 0.062\n",
      "Federated Averaging done\n",
      "Round 55 done\n",
      "training loss: 0.059\n",
      "Federated Averaging done\n",
      "Validation accuracy in round 55: 74 %\n",
      "Round 56 done\n",
      "training loss: 0.046\n",
      "Federated Averaging done\n",
      "Round 57 done\n",
      "training loss: 0.059\n",
      "Federated Averaging done\n",
      "Round 58 done\n",
      "training loss: 0.052\n",
      "Federated Averaging done\n",
      "Round 59 done\n",
      "training loss: 0.071\n",
      "Federated Averaging done\n",
      "Round 60 done\n",
      "training loss: 0.053\n",
      "Federated Averaging done\n",
      "Validation accuracy in round 60: 75 %\n",
      "Round 61 done\n",
      "training loss: 0.058\n",
      "Federated Averaging done\n",
      "Round 62 done\n",
      "training loss: 0.057\n",
      "Federated Averaging done\n",
      "Round 63 done\n",
      "training loss: 0.060\n",
      "Federated Averaging done\n",
      "Round 64 done\n",
      "training loss: 0.055\n",
      "Federated Averaging done\n",
      "Round 65 done\n",
      "training loss: 0.052\n",
      "Federated Averaging done\n",
      "Validation accuracy in round 65: 74 %\n",
      "Round 66 done\n",
      "training loss: 0.048\n",
      "Federated Averaging done\n",
      "Round 67 done\n",
      "training loss: 0.058\n",
      "Federated Averaging done\n",
      "Round 68 done\n",
      "training loss: 0.048\n",
      "Federated Averaging done\n",
      "Round 69 done\n",
      "training loss: 0.047\n",
      "Federated Averaging done\n",
      "Round 70 done\n",
      "training loss: 0.057\n",
      "Federated Averaging done\n",
      "Validation accuracy in round 70: 74 %\n",
      "Round 71 done\n",
      "training loss: 0.048\n",
      "Federated Averaging done\n",
      "Round 72 done\n",
      "training loss: 0.052\n",
      "Federated Averaging done\n",
      "Round 73 done\n",
      "training loss: 0.048\n",
      "Federated Averaging done\n",
      "Round 74 done\n",
      "training loss: 0.042\n",
      "Federated Averaging done\n",
      "Round 75 done\n",
      "training loss: 0.057\n",
      "Federated Averaging done\n",
      "Validation accuracy in round 75: 74 %\n",
      "Round 76 done\n",
      "training loss: 0.050\n",
      "Federated Averaging done\n",
      "Round 77 done\n",
      "training loss: 0.041\n",
      "Federated Averaging done\n",
      "Round 78 done\n",
      "training loss: 0.049\n",
      "Federated Averaging done\n",
      "Round 79 done\n",
      "training loss: 0.047\n",
      "Federated Averaging done\n",
      "Round 80 done\n",
      "training loss: 0.048\n",
      "Federated Averaging done\n",
      "Validation accuracy in round 80: 75 %\n",
      "Round 81 done\n",
      "training loss: 0.043\n",
      "Federated Averaging done\n",
      "Round 82 done\n",
      "training loss: 0.044\n",
      "Federated Averaging done\n",
      "Round 83 done\n",
      "training loss: 0.061\n",
      "Federated Averaging done\n",
      "Round 84 done\n",
      "training loss: 0.046\n",
      "Federated Averaging done\n",
      "Round 85 done\n",
      "training loss: 0.045\n",
      "Federated Averaging done\n",
      "Validation accuracy in round 85: 74 %\n",
      "Round 86 done\n",
      "training loss: 0.043\n",
      "Federated Averaging done\n",
      "Round 87 done\n",
      "training loss: 0.042\n",
      "Federated Averaging done\n",
      "Round 88 done\n",
      "training loss: 0.057\n",
      "Federated Averaging done\n",
      "Round 89 done\n",
      "training loss: 0.044\n",
      "Federated Averaging done\n",
      "Round 90 done\n",
      "training loss: 0.047\n",
      "Federated Averaging done\n",
      "Validation accuracy in round 90: 75 %\n",
      "Round 91 done\n",
      "training loss: 0.038\n",
      "Federated Averaging done\n",
      "Round 92 done\n",
      "training loss: 0.051\n",
      "Federated Averaging done\n",
      "Round 93 done\n",
      "training loss: 0.041\n",
      "Federated Averaging done\n",
      "Round 94 done\n",
      "training loss: 0.045\n",
      "Federated Averaging done\n",
      "Round 95 done\n",
      "training loss: 0.048\n",
      "Federated Averaging done\n",
      "Validation accuracy in round 95: 75 %\n",
      "Round 96 done\n",
      "training loss: 0.059\n",
      "Federated Averaging done\n",
      "Round 97 done\n",
      "training loss: 0.037\n",
      "Federated Averaging done\n",
      "Round 98 done\n",
      "training loss: 0.051\n",
      "Federated Averaging done\n",
      "Round 99 done\n",
      "training loss: 0.041\n",
      "Federated Averaging done\n",
      "Round 100 done\n",
      "training loss: 0.041\n",
      "Federated Averaging done\n",
      "Validation accuracy in round 100: 76 %\n"
     ]
    }
   ],
   "source": [
    "avg_test_loss = []\n",
    "valid_accs = []\n",
    "\n",
    "current_weights = copy.deepcopy(init_weights)\n",
    "\n",
    "for round in range(NUM_ROUNDS):     # iterate thru rounds\n",
    "\n",
    "    current_weights_cpu = {k: v.cpu() for k, v in current_weights.items()}\n",
    "\n",
    "    client_ids = torch.randperm(NUM_CLIENTS)[:CLIENTS_PER_ROUND] # random selection of clients to participate\n",
    "    local_weights = []\n",
    "    temp_avg_loss = 0\n",
    "    for id in client_ids:   # iterate thru clients\n",
    "\n",
    "        state_dict, loss = clients[id].train(NUM_LOCAL_EPOCHS, current_weights)\n",
    "        local_weights.append(state_dict)\n",
    "        temp_avg_loss += loss\n",
    "\n",
    "\n",
    "    avg_test_loss.append(temp_avg_loss / CLIENTS_PER_ROUND)\n",
    "    \n",
    "    print(f\"Round {round+1} done\")\n",
    "    print(f\"training loss: {avg_test_loss[-1]:.3f}\")\n",
    "    # average local weights\n",
    "    #new_weights = {}\n",
    "    #for key in current_weights:\n",
    "    #    new_weights[key] = torch.stack([local_weights[i][key] for i in range(CLIENTS_PER_ROUND)]).sum(0) / CLIENTS_PER_ROUND\n",
    "    new_weights = FedAvg(local_weights)    \n",
    "    print(\"Federated Averaging done\")\n",
    "\n",
    "    current_weights = new_weights\n",
    "\n",
    "    if round % 5 == 4:\n",
    "        net.load_state_dict(current_weights)\n",
    "        net.eval()\n",
    "\n",
    "        correct = 0\n",
    "        total = 0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for (images, labels) in valloader:\n",
    "                images, labels = images.to(device), labels.to(device)\n",
    "                # calculate outputs by running images through the network\n",
    "                outputs = net(images)\n",
    "                # the class with the highest energy is what we choose as prediction\n",
    "                _, predicted = torch.max(outputs, 1)\n",
    "                total += labels.size(0)\n",
    "                correct += (predicted == labels).sum().item()\n",
    "        valid_acc = correct / total\n",
    "        valid_accs.append(valid_acc)\n",
    "        if valid_acc > 0.77:\n",
    "            print(f\"validation accuracy reached 77% in {round+1:d} rounds\")\n",
    "            break\n",
    "        print(f'Validation accuracy in round {round+1:d}: {100 * correct // total} %')\n",
    "\n",
    "\n",
    "torch.save(net.state_dict(), \"data/models/fedavg_cifar10.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net = SmallCNN().to(device)\n",
    "net.load_state_dict(torch.load(\"data/models/fedavg_cifar10.pth\", weights_only=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'avg_test_loss' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m fig, axs \u001b[38;5;241m=\u001b[39m plt\u001b[38;5;241m.\u001b[39msubplots(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m, figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m15\u001b[39m, \u001b[38;5;241m5\u001b[39m))\n\u001b[1;32m----> 2\u001b[0m axs[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mplot(\u001b[43mavg_test_loss\u001b[49m)\n\u001b[0;32m      3\u001b[0m axs[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mset_title(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAverage loss\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      4\u001b[0m axs[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mset_xlabel(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRound\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'avg_test_loss' is not defined"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "fig, axs = plt.subplots(1, 2, figsize=(15, 5))\n",
    "axs[0].plot(avg_test_loss)\n",
    "axs[0].set_title(\"Average loss\")\n",
    "axs[0].set_xlabel(\"Round\")\n",
    "axs[0].set_ylabel(\"Loss\")   \n",
    "\n",
    "axs[1].plot(np.arange(1, NUM_ROUNDS+1, 5), valid_accs)\n",
    "axs[1].set_title(\"Validation accuracy\")\n",
    "axs[1].set_xlabel(\"Round\")\n",
    "axs[1].set_ylabel(\"Accuracy\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the 10000 test images: 74 %\n",
      "Accuracy for class: plane is 78.2 %\n",
      "Accuracy for class: car   is 87.9 %\n",
      "Accuracy for class: bird  is 59.2 %\n",
      "Accuracy for class: cat   is 51.7 %\n",
      "Accuracy for class: deer  is 71.3 %\n",
      "Accuracy for class: dog   is 59.2 %\n",
      "Accuracy for class: frog  is 88.3 %\n",
      "Accuracy for class: horse is 81.5 %\n",
      "Accuracy for class: ship  is 86.5 %\n",
      "Accuracy for class: truck is 81.4 %\n"
     ]
    }
   ],
   "source": [
    "net.eval()\n",
    "\n",
    "correct = 0\n",
    "total = 0\n",
    "# since we're not training, we don't need to calculate the gradients for our outputs\n",
    "with torch.no_grad():\n",
    "    for (images, labels) in testloader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        # calculate outputs by running images through the network\n",
    "        outputs = net(images)\n",
    "        # the class with the highest energy is what we choose as prediction\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print(f'Accuracy of the network on the 10000 test images: {100 * correct // total} %')\n",
    "\n",
    "# prepare to count predictions for each class\n",
    "correct_pred = {classname: 0 for classname in classes}\n",
    "total_pred = {classname: 0 for classname in classes}\n",
    "\n",
    "# again no gradients needed\n",
    "with torch.no_grad():\n",
    "    for (images, labels) in testloader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        outputs = net(images)\n",
    "        _, predictions = torch.max(outputs, 1)\n",
    "        # collect the correct predictions for each class\n",
    "        for label, prediction in zip(labels, predictions):\n",
    "            if label == prediction:\n",
    "                correct_pred[classes[label]] += 1\n",
    "            total_pred[classes[label]] += 1\n",
    "\n",
    "\n",
    "# print accuracy for each class\n",
    "for classname, correct_count in correct_pred.items():\n",
    "    accuracy = 100 * float(correct_count) / total_pred[classname]\n",
    "    print(f'Accuracy for class: {classname:5s} is {accuracy:.1f} %')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "FLenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
